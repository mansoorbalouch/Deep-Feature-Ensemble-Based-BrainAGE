{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'TrainTestGLT' from '/media/dataanalyticlab/Drive2/MANSOOR/Neuroimaging_Project/Code/Brain_Age_Estimation/DL_based_BAE/GlobalLocalTransformer/TrainTestGLT.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import GlobalLocalTransformer\n",
    "import vgg\n",
    "from GlobalLocalTransformer import *\n",
    "import torch as nn\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy.ndimage as nd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score,mean_absolute_error\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import TrainTestGLT\n",
    "from TrainTestGLT import *\n",
    "import imp\n",
    "imp.reload(GlobalLocalTransformer)\n",
    "imp.reload(vgg)\n",
    "imp.reload(TrainTestGLT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data matrix loaded... shape:  (20, 121, 145, 121, 1)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "src = \"/media/dataanalyticlab/Drive2/MANSOOR/Dataset/Test/\"\n",
    "X = np.load(src + \"VBM_OpenBHB.npy\")\n",
    "Y = pd.read_csv(src + \"SubInfoOpenBHB.csv\")\n",
    "print(\"Data matrix loaded... shape: \", X.shape )\n",
    "labels = Y.loc[:,\"age\"]\n",
    "x = X[:,:,:,60:65,0]\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 5, 121, 145])\n",
      "torch.Size([4, 5, 121, 145])\n",
      "torch.Size([16]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x,labels, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_train = X_train.permute(0,3,1,2)\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "X_test = torch.from_numpy(X_test)\n",
    "X_test = X_test.permute(0,3,1,2)\n",
    "print(X_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "Y_train = torch.from_numpy(np.array(Y_train))\n",
    "Y_test = torch.from_numpy(np.array(Y_test))\n",
    "\n",
    "print(Y_train.shape, Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(list(zip(X_train, Y_train)), batch_size=5, shuffle=True)\n",
    "test_dataloader = DataLoader(X_test, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dataanalyticlab/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: tensor(19.3501, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "backward pass completed...\n",
      "Epoch 0 completed\n",
      "Epoch: 0 Mean Absolute Error (MAE): 25.32518721515599\n",
      "Epoch: 1 Loss: tensor(17.7104, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "backward pass completed...\n",
      "Epoch 1 completed\n",
      "Epoch: 1 Mean Absolute Error (MAE): 24.600474847878335\n",
      "Epoch: 2 Loss: tensor(16.1519, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "backward pass completed...\n",
      "Epoch 2 completed\n",
      "Epoch: 2 Mean Absolute Error (MAE): 23.937253197037744\n",
      "Epoch: 3 Loss: tensor(14.5911, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "backward pass completed...\n",
      "Epoch 3 completed\n",
      "Epoch: 3 Mean Absolute Error (MAE): 23.603286593955918\n",
      "Epoch: 4 Loss: tensor(13.2688, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "backward pass completed...\n",
      "Epoch 4 completed\n",
      "Epoch: 4 Mean Absolute Error (MAE): 23.419284455853585\n"
     ]
    }
   ],
   "source": [
    "regression_model = nn.Linear(13, 1)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "iters, losses, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "regression_model = regression_model.double()\n",
    "# output_tensors = output_tensors.double()\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Loop through the number of epochs\n",
    "for epoch in range(5):\n",
    "    total_loss = 0  # Initialize loss for the entire epoch\n",
    "    total_mae = 0.0   # Initialize the total MAE for the entire epoch\n",
    "    optimizer.zero_grad()  # a clean up step for PyTorch\n",
    "\n",
    "    # Training loop\n",
    "    regression_model.train()\n",
    "    zlist = model(X_train)             # forward pass\n",
    "    output_tensors = torch.cat(zlist, dim=1)\n",
    "    # Loop through the batches and update the gradients\n",
    "\n",
    "    # for inputs, labels in train_dataloader:\n",
    "\n",
    "\n",
    "    for i in range(len(X_train)):\n",
    "        final_output = regression_model(output_tensors[i])\n",
    "        loss = criterion(final_output, Y_train[i])  # Compute the loss for each sample\n",
    "        total_loss += loss  # Accumulate the loss for the entire batch\n",
    "\n",
    "    avg_loss = total_loss / len(X_train)  # Calculate the average loss for the batch\n",
    "    print(\"Epoch:\", epoch, \"Loss:\", avg_loss)\n",
    "\n",
    "    avg_loss.backward(retain_graph=True)  # Backward pass (compute parameter updates)\n",
    "    print(\"backward pass completed...\")\n",
    "    optimizer.step()\n",
    "    print(\"Epoch\", epoch, \"completed\")\n",
    "\n",
    "    # Validation loop \n",
    "    regression_model.eval()  # Set the model to evaluation model\n",
    "    total_samples = 0\n",
    "    zlist = model(X_test)             # forward pass\n",
    "    output_tensors = torch.cat(zlist, dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(X_test)):\n",
    "            outputs = regression_model(output_tensors[i])\n",
    "            mae = torch.mean(torch.abs(outputs - Y_test[i]))\n",
    "            total_mae += mae.item()\n",
    "            total_samples += 1\n",
    "\n",
    "        avg_mae = total_mae / total_samples  # Calculate the average MAE for the epoch\n",
    "        print(\"Epoch:\", epoch, \"Mean Absolute Error (MAE):\", avg_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, X_set, Y_set):\n",
    "   \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(len(X_set)):\n",
    "        output = model(X_set) # We don't need to run F.softmax\n",
    "        pred = output[0].max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(Y_set.view_as(pred)).sum().item()\n",
    "        total += X_set[i].shape[0]\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GlobalLocalBrainAge(5,\n",
    "                        patch_size=64,\n",
    "                        step=32,\n",
    "                        nblock=6,\n",
    "                        backbone='vgg8')\n",
    "\n",
    "model = model.double()\n",
    "acc = train(model, X_train, Y_train)\n",
    "# zlist = model(x)\n",
    "# for z in zlist:\n",
    "    # print(z.shape)\n",
    "    \n",
    "# Assuming `output_tensors` is a list of 'n' tensors, each of size mx1, representing predictions for 'n' patches.\n",
    "# You can concatenate them along the patch dimension (n) to form a single tensor of size m x n x 1.\n",
    "# output_tensors = torch.cat(zlist, dim=1)\n",
    "\n",
    "# Now, compute the mean along the patch dimension (n) to obtain a single tensor of size mx1 for each sample.\n",
    "# aggregated_predictions = torch.mean(output_tensors, dim=1)\n",
    "# aggregated_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], dtype=torch.float64, grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "prob = F.softmax(zlist[0][6], dim=0)\n",
    "print(prob)\n",
    "# print(sum(prob[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
